---
title: "Improving Inconspicuous Attributes Modeling for Person Search by Language"
collection: publications
permalink: /publication/TIP_IAM
excerpt: ''
venue: 'IEEE Transactions on Image Processing (TIP)'
date: 2023-06-20
paperurl: ''
citation: 'Kai Niu, Tao Huang, <b>Linjiang Huang (Corresponding Author)</b>, Liang Wang, Yanning Zhang. &quot;Improving Inconspicuous Attributes Modeling for Person Search by Language;.<i>IEEE Transactions on Image Processing</i> <b>TIP 2023</b>.'
---

## Abstract
Person search by language aims to retrieve the interested pedestrian images based on natural language sentences. Although great efforts have been made to address the cross-modal heterogeneity, most of the current solutions suffer from only capturing salient attributes while ignoring inconspicuous ones, being weak in distinguishing very similar pedestrians. In this work, we propose the Adaptive Salient Attribute Mask Network (ASAMN) to adaptively mask the salient attributes for cross-modal alignments, and therefore induce the model to simultaneously focus on inconspicuous attributes. Specifically, we consider the uni-modal and cross-modal relations for masking salient attributes in the Uni-modal Salient Attribute Mask (USAM) and Cross-modal Salient Attribute Mask (CSAM) modules, respectively. Then the Attribute Modeling Balance (AMB) module is presented to randomly select a proportion of masked features for cross-modal alignments, ensuring the balance of modeling capacity of both salient attributes and inconspicuous ones. Extensive experiments and analyses have been carried out to validate the effectiveness and generalization capacity of our proposed ASAMN method, and we have obtained the state-of-the-art retrieval performance on the widely-used CUHK-PEDES and ICFG-PEDES benchmarks.
